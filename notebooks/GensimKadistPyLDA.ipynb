{
 "metadata": {
  "name": "",
  "signature": "sha256:843b02dec9b1137afc4d8a73a1f718a70d361a2d650ebeb75a5e363e1cc0168d"
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from glob import glob\n",
      "import re\n",
      "import string\n",
      "import funcy as fp\n",
      "from gensim import models\n",
      "from gensim.corpora import Dictionary, MmCorpus\n",
      "import nltk\n",
      "import pandas as pd\n",
      "from gensim import corpora, models, similarities\n",
      "from gensim.models import hdpmodel, ldamodel, lsimodel\n",
      "import sys\n",
      "import codecs\n",
      "import json\n",
      "from nltk.corpus import stopwords\n",
      "from textblob import TextBlob\n",
      "import pyLDAvis.gensim as gensimvis\n",
      "import pyLDAvis"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "stoplist = stopwords.words('english')\n",
      "stoplist.extend(stopwords.words('french'))\n",
      "stoplist.extend([\"also\",\"said\",\"work\",\"one\",\"two\",\"three\", \"les\", \"like\"])"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def tokenize(line):\n",
      "  np = TextBlob(line.encode('ascii', 'ignore')).noun_phrases\n",
      "  return [str(w).lower() for w in np + allcaps if len(w) > 2]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def make_documents(data):\n",
      "  return [' '.join(x['generated_tags']) for x in data]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "with codecs.open('kadist.json', 'r', encoding='utf-8') as f:\n",
      "  data = json.loads(f.read())\n",
      "  documents = make_documents(data)\n",
      "  dictionary = corpora.Dictionary(text.encode('ascii', 'ignore').lower().split() for text in documents)\n",
      "  dictionary.filter_extremes(no_below=5, no_above=0.5, keep_n=100000)\n",
      "  stop_ids = [dictionary.token2id[stopword] for stopword in stoplist if stopword in dictionary.token2id]\n",
      "  dictionary.filter_tokens(stop_ids) # remove stop words and words that appear only once\n",
      "  dictionary.compactify()\n",
      "\n",
      "  corpus = [dictionary.doc2bow(doc.split()) for doc in documents]\n",
      "\n",
      "  tfidf = models.TfidfModel(corpus, normalize=True)\n",
      "\n",
      "  corpus_tfidf = tfidf[corpus]\n",
      "\n",
      "  print 'LDA', '*'*50\n",
      "  lda = ldamodel.LdaModel(corpus, id2word=dictionary, num_topics=200, passes=10)\n",
      "  for topic in lda.show_topics(num_topics=200, num_words=10, log=False, formatted=False):\n",
      "    print [x[1] for x in topic]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "vis_data = gensimvis.prepare(lda, corpus, dictionary)\n",
      "pyLDAvis.display(vis_data)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    }
   ],
   "metadata": {}
  }
 ]
}